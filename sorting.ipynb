{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Define paths\n",
    "# dataset_path = r\"D:\\catdogdata\\cat_dog\"\n",
    "# output_path = r\"D:/CATDOGSORTED/\"  \n",
    "\n",
    "# # Create folders for 'cats' and 'dogs'\n",
    "# cat_folder = os.path.join(output_path, \"cats\")\n",
    "# dog_folder = os.path.join(output_path, \"dogs\")\n",
    "\n",
    "# os.makedirs(cat_folder, exist_ok=True)\n",
    "# os.makedirs(dog_folder, exist_ok=True)\n",
    "\n",
    "# # Move images to respective folders\n",
    "# for filename in os.listdir(dataset_path):\n",
    "#     if filename.lower().startswith(\"cat\"):\n",
    "#         shutil.move(os.path.join(dataset_path, filename), os.path.join(cat_folder, filename))\n",
    "#     elif filename.lower().startswith(\"dog\"):\n",
    "#         shutil.move(os.path.join(dataset_path, filename), os.path.join(dog_folder, filename))\n",
    "\n",
    "# print(\"Images successfully sorted into 'cats' and 'dogs' folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define source and destination paths\n",
    "dataset_path = r\"C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\"\n",
    "train_path = r\"C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train\"\n",
    "val_path = r\"C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\val\"\n",
    "\n",
    "# Define categories\n",
    "categories = [\"cats\", \"dogs\"]\n",
    "\n",
    "# Split ratio\n",
    "split_ratio = 0.8  # 80% train, 20% validation\n",
    "\n",
    "# Create train and val directories\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(train_path, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_path, category), exist_ok=True)\n",
    "\n",
    "    # Get all images in category folder\n",
    "    images = os.listdir(os.path.join(dataset_path, category))\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Split data\n",
    "    train_size = int(len(images) * split_ratio)\n",
    "    train_images = images[:train_size]\n",
    "    val_images = images[train_size:]\n",
    "\n",
    "    # Move images to train and val folders\n",
    "    for img in train_images:\n",
    "        shutil.move(os.path.join(dataset_path, category, img), os.path.join(train_path, category, img))\n",
    "\n",
    "    for img in val_images:\n",
    "        shutil.move(os.path.join(dataset_path, category, img), os.path.join(val_path, category, img))\n",
    "\n",
    "print(\"✅ Dataset successfully split into train and validation sets!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl.metadata (2.3 kB)\n",
      "Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "   ---------------------------------------- 0.0/14.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.4/14.7 MB 22.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.1/14.7 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.7 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.7/14.7 MB 20.0 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.23.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow\n",
      "  Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl.metadata (9.1 kB)\n",
      "Downloading pillow-11.2.1-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 22.1 MB/s eta 0:00:00\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-11.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\victus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scipy) (1.23.5)\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.7/46.2 MB 31.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.5/46.2 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.7/46.2 MB 27.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 21.5/46.2 MB 27.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 27.5/46.2 MB 27.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.6/46.2 MB 28.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 39.1/46.2 MB 27.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.6/46.2 MB 27.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 26.7 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing corrupted file: C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train\\cats\\666.jpg\n",
      "Removing corrupted file: C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train\\dogs\\11702.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing corrupted file: C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train\\dogs\\Thumbs.db\n",
      "Removing corrupted file: C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\val\\cats\\Thumbs.db\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def remove_corrupted_images(directory):\n",
    "    for folder_name in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()  # Will raise an exception if not an image\n",
    "            except (IOError, SyntaxError, Image.UnidentifiedImageError):\n",
    "                print(f\"Removing corrupted file: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "remove_corrupted_images(r'C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train')\n",
    "remove_corrupted_images(r'C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19997 images belonging to 2 classes.\n",
      "Found 19997 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 314s 501ms/step - loss: 0.6328 - accuracy: 0.6356 - val_loss: 0.5177 - val_accuracy: 0.7434\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 310s 496ms/step - loss: 0.5109 - accuracy: 0.7511 - val_loss: 0.4466 - val_accuracy: 0.7908\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 395s 631ms/step - loss: 0.4533 - accuracy: 0.7868 - val_loss: 0.3962 - val_accuracy: 0.8235\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 325s 520ms/step - loss: 0.4183 - accuracy: 0.8088 - val_loss: 0.3537 - val_accuracy: 0.8416\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1176s 2s/step - loss: 0.3938 - accuracy: 0.8207 - val_loss: 0.3513 - val_accuracy: 0.8450\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 860s 1s/step - loss: 0.3638 - accuracy: 0.8414 - val_loss: 0.3012 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 307s 491ms/step - loss: 0.3376 - accuracy: 0.8506 - val_loss: 0.2916 - val_accuracy: 0.8769\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 327s 523ms/step - loss: 0.3190 - accuracy: 0.8605 - val_loss: 0.2710 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 4214s 7s/step - loss: 0.2977 - accuracy: 0.8744 - val_loss: 0.2511 - val_accuracy: 0.8951\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 299s 478ms/step - loss: 0.2894 - accuracy: 0.8782 - val_loss: 0.2500 - val_accuracy: 0.8940\n",
      "✅ Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "train_dir = r\"C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train\"\n",
    "val_dir = r\"C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\train\"\n",
    "\n",
    "# Image Data Generators (Augmentation)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load images\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=32, class_mode=\"binary\")\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(150, 150), batch_size=32, class_mode=\"binary\")\n",
    "\n",
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (Cats vs. Dogs)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "\n",
    "# Save model\n",
    "model.save(\"cat_dog_classifier.h5\")\n",
    "print(\"✅ Model training complete and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "🐱 It's a Cat!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"cat_dog_classifier.h5\")\n",
    "\n",
    "# Load and preprocess test image\n",
    "img_path = r\"C:\\Vishnu\\PROJECTS\\Cat_Or_Dog\\data\\val\\cats\\12475.jpg\"\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "prediction\n",
    "\n",
    "if prediction > 0.5:\n",
    "    print(\"🐶 It's a Dog!\")\n",
    "else:\n",
    "    print(\"🐱 It's a Cat!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
